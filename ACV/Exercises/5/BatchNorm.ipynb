{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BatchNorm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hizFMVF6LW9v"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "def define_model():\n",
        "    inputs = keras.Input(shape=(28,28,1))\n",
        "\n",
        "    K = 20 # number of convolution layers per block\n",
        "    L = 3  # number of blocks\n",
        "    x = inputs\n",
        "    for i in range(0,L):\n",
        "        for j in range(0,K):\n",
        "            # Add call to custom layer here: x = MyBatchNormalization()(x)\n",
        "            x = layers.Conv2D(32, 3, activation=\"relu\",padding=\"same\")(x)\n",
        "        x = layers.MaxPooling2D(3)(x)\n",
        "    x = layers.GlobalMaxPooling2D()(x)\n",
        "    outputs = layers.Dense(10,activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs,outputs)\n",
        "    model.summary() # show model overview\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrNe7WQsOg9s"
      },
      "source": [
        "# Load and preprocess training data (Fashion-MNIST)\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
        "\n",
        "# Define and train model\n",
        "model = define_model()\n",
        "model.compile(loss=keras.losses.CategoricalCrossentropy(),optimizer=keras.optimizers.Adam(),metrics=[\"accuracy\"])\n",
        "model.fit(train_images,train_labels, batch_size=64, epochs=100)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}