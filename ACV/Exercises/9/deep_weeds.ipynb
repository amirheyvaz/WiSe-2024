{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the full executable code for the solution to this task.\n",
        "I just did not have enough time to run it and present results. (I also came across some warning regarding the data-generator which needs furthur debugging)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tnxkYQ-HdM8",
        "outputId": "468c7949-e89c-41db-a37b-17e7e68acc4b"
      },
      "outputs": [],
      "source": [
        "############\n",
        "# Deep weeds is currently only available in tfds-nightly\n",
        "############\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from PIL import Image\n",
        "\n",
        "# Loads deep weeds data. \n",
        "# Can subsample the data with <fraction> parameter to prevent exhausting memory\n",
        "def load_deepweeds(fraction=1.0):\n",
        "  train_x = []\n",
        "  train_y = []\n",
        "  ds = tfds.load('deep_weeds', split='train', as_supervised=True)\n",
        "  for image,label in tfds.as_numpy(ds):\n",
        "    if np.random.uniform(0,1) < fraction:\n",
        "      train_x.append(np.array(Image.fromarray(image).resize((224,224))))\n",
        "      train_y.append(label)\n",
        "  train_x = np.array(train_x)/255.0\n",
        "  train_y = tf.keras.utils.to_categorical(np.array(train_y))\n",
        "  return train_x, train_y\n",
        "\n",
        "\n",
        "train_x, train_y = load_deepweeds(fraction=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "import csv\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import classification_report\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, Conv2DTranspose, concatenate, Dropout, MaxPooling2D\n",
        "\n",
        "# Global paths\n",
        "OUTPUT_DIRECTORY = \"./outputs/\"\n",
        "LABEL_DIRECTORY = \"./labels/\"\n",
        "MODEL_DIRECTORY = \"./models/\"\n",
        "IMG_DIRECTORY = \"./images/\"\n",
        "\n",
        "# Global variables\n",
        "RAW_IMG_SIZE = (256, 256)\n",
        "IMG_SIZE = (224, 224)\n",
        "INPUT_SHAPE = (IMG_SIZE[0], IMG_SIZE[1], 3)\n",
        "MAX_EPOCH = 20\n",
        "BATCH_SIZE = 32\n",
        "FOLDS = 5\n",
        "STOPPING_PATIENCE = 32\n",
        "LR_PATIENCE = 16\n",
        "INITIAL_LR = 0.0001\n",
        "CLASSES = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "CLASS_NAMES = ['Chinee Apple',\n",
        "                'Lantana',\n",
        "                'Parkinsonia',\n",
        "                'Parthenium',\n",
        "                'Prickly Acacia',\n",
        "                'Rubber Vine',\n",
        "                'Siam Weed',\n",
        "                'Snake Weed',\n",
        "                'Negatives']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def crop(img, size):\n",
        "    \"\"\"\n",
        "    Crop the image concentrically to the desired size.\n",
        "    :param img: Input image\n",
        "    :param size: Required crop image size\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    (h, w, c) = img.shape\n",
        "    x = int((w - size[0]) / 2)\n",
        "    y = int((h - size[1]) / 2)\n",
        "    return img[y:(y + size[1]), x:(x + size[0]), :]\n",
        "\n",
        "\n",
        "def crop_generator(batches, size):\n",
        "    \"\"\"\n",
        "    Take as input a Keras ImageGen (Iterator) and generate random\n",
        "    crops from the image batches generated by the original iterator\n",
        "    :param batches: Batches of images to be cropped\n",
        "    :param size: Size to be cropped to\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        batch_x, batch_y = next(batches)\n",
        "        (b, h, w, c) = batch_x.shape\n",
        "        batch_crops = np.zeros((b, size[0], size[1], c))\n",
        "        for i in range(b):\n",
        "            batch_crops[i] = crop(batch_x[i], (size[0], size[1]))\n",
        "        yield (batch_crops, batch_y)\n",
        "\n",
        "\n",
        "def get_data():\n",
        "    train_dataframe = None\n",
        "    val_dataframe = None\n",
        "    test_dataframe = None\n",
        "    # K fold cross validation, saving outputs for each fold\n",
        "    for k in range(FOLDS):\n",
        "\n",
        "        # Prepare training, validation and testing labels for kth fold\n",
        "        train_label_file = \"{}train_subset{}.csv\".format(LABEL_DIRECTORY, k)\n",
        "        val_label_file = \"{}val_subset{}.csv\".format(LABEL_DIRECTORY, k)\n",
        "        test_label_file = \"{}test_subset{}.csv\".format(LABEL_DIRECTORY, k)\n",
        "        if k == 0:\n",
        "            train_dataframe = pd.read_csv(train_label_file)\n",
        "        else:\n",
        "            train_dataframe = pd.concat([train_dataframe, pd.read_csv(train_label_file)], axis=0, ignore_index=True)\n",
        "        if k == 0:\n",
        "            val_dataframe = pd.read_csv(val_label_file)\n",
        "        else:\n",
        "            val_dataframe = pd.concat([val_dataframe, pd.read_csv(val_label_file)], axis=0, ignore_index=True)\n",
        "        if k == 0:\n",
        "            test_dataframe = pd.read_csv(test_label_file)\n",
        "        else:\n",
        "            test_dataframe = pd.concat([test_dataframe, pd.read_csv(test_label_file)], axis=0, ignore_index=True)\n",
        "\n",
        "    train_image_count = train_dataframe.shape[0]\n",
        "    val_image_count = val_dataframe.shape[0]\n",
        "    test_image_count = test_dataframe.shape[0]\n",
        "    \n",
        "    train_dataframe['Label'] = train_dataframe['Label'].astype(str)\n",
        "    val_dataframe['Label'] = val_dataframe['Label'].astype(str)\n",
        "    test_dataframe['Label'] = test_dataframe['Label'].astype(str)\n",
        "\n",
        "    train_data_generator = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        fill_mode=\"constant\",\n",
        "        shear_range=0.2,\n",
        "        zoom_range=(0.5, 1),\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=360,\n",
        "        channel_shift_range=25,\n",
        "        brightness_range=(0.75, 1.25)).flow_from_dataframe(\n",
        "        dataframe=train_dataframe,\n",
        "        directory=IMG_DIRECTORY,\n",
        "        x_col='Filename',\n",
        "        y_col='Label',\n",
        "        target_size=RAW_IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        has_ext=True,\n",
        "        classes=CLASSES,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    # Load validation images in batches from directory and apply rescaling\n",
        "    val_data_generator =  ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        fill_mode=\"constant\",\n",
        "        shear_range=0.2,\n",
        "        zoom_range=(0.5, 1),\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=360,\n",
        "        channel_shift_range=25,\n",
        "        brightness_range=(0.75, 1.25)).flow_from_dataframe(\n",
        "        val_dataframe,\n",
        "        IMG_DIRECTORY,\n",
        "        x_col=\"Filename\",\n",
        "        y_col=\"Label\",\n",
        "        target_size=RAW_IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,  \n",
        "        classes=CLASSES,\n",
        "        class_mode='categorical',\n",
        "        has_ext=True)\n",
        "\n",
        "    # Load test images in batches from directory and apply rescaling\n",
        "    test_data_generator = ImageDataGenerator(rescale=1. / 255).flow_from_dataframe(\n",
        "        test_dataframe,\n",
        "        IMG_DIRECTORY,\n",
        "        x_col=\"Filename\",\n",
        "        y_col=\"Label\",\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        has_ext=True,\n",
        "        shuffle=False,\n",
        "        classes=CLASSES,\n",
        "        class_mode='categorical')\n",
        "\n",
        "    # Crop augmented images from 256x256 to 224x224\n",
        "    train_data_generator = crop_generator(train_data_generator, IMG_SIZE)\n",
        "    val_data_generator = crop_generator(val_data_generator, IMG_SIZE)\n",
        "    \n",
        "    \n",
        "    return train_data_generator, val_data_generator, test_data_generator , train_image_count,\\\n",
        "        val_image_count, test_image_count\n",
        "\n",
        "\n",
        "def get_left_UNET():\n",
        "    inputs = tf.keras.Input(shape=INPUT_SHAPE)\n",
        "\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    # Bottom layer\n",
        "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same', name=\"last_conv_layer\")(conv5)\n",
        "    x = GlobalAveragePooling2D(name='avg_pool')(conv5)\n",
        "    x = Dense(1024, activation='relu', name=\"fully_connected\")(x)\n",
        "    outputs = Dense(len(CLASSES), activation='softmax', name='output')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)    \n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(train_data_generator, val_data_generator, test_data_generator , train_image_count,\\\n",
        "        val_image_count, test_image_count, model, show_results=False, evaluate=False):\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=INITIAL_LR), metrics=['accuracy'])\n",
        "    history = model.fit(\n",
        "                x=train_data_generator,\n",
        "                batch_size = BATCH_SIZE,\n",
        "                steps_per_epoch=train_image_count // BATCH_SIZE,\n",
        "                epochs=MAX_EPOCH,\n",
        "                validation_data=val_data_generator,\n",
        "                validation_steps=val_image_count // BATCH_SIZE,\n",
        "                shuffle=False)\n",
        "    if show_results:\n",
        "        plt.plot(history.history['loss'], label='Training Loss')\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training and Validation Losses')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    if evaluate:\n",
        "        predictions = model.predict_generator(test_data_generator, test_image_count // BATCH_SIZE + 1)\n",
        "        y_true = test_data_generator.classes\n",
        "        y_pred = np.argmax(predictions, axis=1)\n",
        "        y_pred[np.max(predictions, axis=1) < 1 / 9] = 8  # Assign predictions worse than random guess to negative class\n",
        "        report = classification_report(y_true, y_pred, labels=CLASSES, target_names=CLASS_NAMES)\n",
        "        print(report)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 validated image filenames belonging to 9 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "h:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 52525 invalid image filename(s) in x_col=\"Filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 validated image filenames belonging to 9 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "h:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 17511 invalid image filename(s) in x_col=\"Filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 validated image filenames belonging to 9 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "h:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 17509 invalid image filename(s) in x_col=\"Filename\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_data_generator, val_data_generator, test_data_generator , train_image_count,\\\n",
        "        val_image_count, test_image_count = get_data()\n",
        "\n",
        "model = get_left_UNET()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train_model(train_data_generator, val_data_generator, test_data_generator , train_image_count,\\\n",
        "        val_image_count, test_image_count, model, show_results=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "def original_Unet():\n",
        "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    # Bottom layer\n",
        "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same', name=\"last_conv_layer\")(conv5)\n",
        "\n",
        "    # Decoder\n",
        "    up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
        "    merge6 = concatenate([conv4, up6], axis=-1)\n",
        "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(merge6)\n",
        "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
        "    merge7 = concatenate([conv3, up7], axis=-1)\n",
        "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge7)\n",
        "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
        "    merge8 = concatenate([conv2, up8], axis=-1)\n",
        "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge8)\n",
        "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
        "    merge9 = concatenate([conv1, up9], axis=-1)\n",
        "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge9)\n",
        "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Conv2D(3, (1, 1), activation='softmax')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def load_segmentation_data():\n",
        "    data = np.load('segmentation_data.npz')\n",
        "    train_x = data['train_x']\n",
        "    train_y = data['train_y']\n",
        "    test_x = data['test_x']\n",
        "    test_y = data['test_y']\n",
        "    return train_x, train_y, test_x, test_y\n",
        "\n",
        "\n",
        "train_x, train_y, test_x, test_y = load_segmentation_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "segment_model = original_Unet()\n",
        "for layer_source, layer_dest in zip(model.layers, segment_model.layers):\n",
        "    layer_dest.set_weights(layer_source.get_weights())\n",
        "    layer_dest.trainable = False\n",
        "    if layer_source.name == \"last_conv_layer\":\n",
        "        break\n",
        "\n",
        "segment_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "segment_model.fit(train_x, train_y, epochs=20, batch_size=8)\n",
        "\n",
        "for layer in segment_model.layers:\n",
        "    layer_dest.trainable = True\n",
        "    \n",
        "segment_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "segment_model.fit(train_x, train_y, epochs=20, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_x, test_y)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I think that it would perform better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "deep_weeds.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
