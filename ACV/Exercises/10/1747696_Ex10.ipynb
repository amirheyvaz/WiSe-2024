{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdht4UhekNMU",
        "outputId": "8fce5a16-94bf-48a5-b7c5-781e1e665eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 13s 71ms/step - loss: 0.5866 - accuracy: 0.8173 - val_loss: 0.1524 - val_accuracy: 0.9540\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 11s 68ms/step - loss: 0.2185 - accuracy: 0.9378 - val_loss: 0.0970 - val_accuracy: 0.9695\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 11s 71ms/step - loss: 0.1500 - accuracy: 0.9560 - val_loss: 0.0868 - val_accuracy: 0.9733\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 11s 70ms/step - loss: 0.1157 - accuracy: 0.9628 - val_loss: 0.0696 - val_accuracy: 0.9778\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 10s 67ms/step - loss: 0.1047 - accuracy: 0.9692 - val_loss: 0.0644 - val_accuracy: 0.9788\n",
            "True class:  7\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "Predictive probabilities:\n",
            "[0.0000000019 0.0000000157 0.0000001817 0.0000004636 0.\n",
            " 0.0000000001 0.           0.99999905   0.0000000012 0.0000002721]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)\n",
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import IPython.display \n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "\n",
        "# simple CNN for MNIST data set\n",
        "def define_model():\n",
        "    inputs = tf.keras.Input(shape=(28,28,1),name='inputs')\n",
        "    x = tf.keras.layers.Conv2D(32,kernel_size=3,activation='relu', name = \"Conv2D_1\")(inputs)\n",
        "    x = tf.keras.layers.Conv2D(64,kernel_size=3,activation='relu', name = \"Conv2D_2\")(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu', name = \"Dense_1\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    outputs = tf.keras.layers.Dense(10, name = \"Dense_2\")(x) # no softmax\n",
        "    model = keras.Model(inputs,outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Load and preprocess training data (MNIST)\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
        "# Subset the data to use only 10,000 samples for training\n",
        "num_samples = 10000\n",
        "train_images = train_images[:num_samples]\n",
        "train_labels = train_labels[:num_samples]\n",
        "test_images = test_images[:num_samples]\n",
        "test_labels = test_labels[:num_samples]\n",
        "# Define and train model\n",
        "model = define_model()\n",
        "model.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=True),optimizer=keras.optimizers.Adam(),metrics=[\"accuracy\"])\n",
        "model.fit(train_images,train_labels, validation_data=(test_images,test_labels),batch_size=64, epochs=5)\n",
        "\n",
        "\n",
        "# Let's look at first test image\n",
        "x0 = test_images[0:1]\n",
        "Image.fromarray(np.uint8(255*cm.gray(np.squeeze(x0)))).save('x0.png')\n",
        "IPython.display.Image('x0.png')\n",
        "\n",
        "y0 = test_labels[0:1]\n",
        "print('True class: % i' % np.argmax(y0))\n",
        "predictions = model.predict(x0)\n",
        "print('Predictive probabilities:') \n",
        "with np.printoptions(precision=10, suppress=True):\n",
        "    print(np.squeeze(tf.nn.softmax(predictions)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "Predicted class: 7\n",
            "The Norm of the perturbation is 0.3021661043167114\n"
          ]
        }
      ],
      "source": [
        "# Function to define the model with a perturbation layer\n",
        "def define_attack_model():\n",
        "    inputs = tf.keras.Input(shape=(28, 28, 1), name='inputs')\n",
        "    \n",
        "    # Perturbation layer with 28*28 learnable weights\n",
        "    perturbation = tf.keras.layers.Conv2D(1, kernel_size=(28, 28), activation='linear', use_bias=False, name=\"perturbation\",\n",
        "                                        kernel_regularizer=tf.keras.regularizers.l2(1))(inputs)\n",
        "    \n",
        "    # Add perturbation to the input\n",
        "    x = layers.Add(name=\"addition\")([inputs, perturbation])\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu', name = \"Conv2D_1\")(x)\n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', name = \"Conv2D_2\")(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu', name = \"Dense_1\")(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    outputs = tf.keras.layers.Dense(10, name = \"Dense_2\")(x)  # Linear activation for class scores\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Custom loss function based on Carlini-Wagner criterion\n",
        "def custom_loss(y_true, y_pred, k=2, lambda_=0.5):\n",
        "\n",
        "    t = tf.argmax(y_true, axis=1)\n",
        "    \n",
        "    f_t = tf.reduce_max(y_pred * y_true, axis=1)  # Score for the true class\n",
        "    \n",
        "    max_other_classes = tf.reduce_max(y_pred * (1 - y_true), axis=1)\n",
        "    \n",
        "    loss = lambda_ * tf.maximum(max_other_classes - f_t, -k)\n",
        "    \n",
        "    return loss\n",
        "\n",
        "\n",
        "# Define and train the attack model\n",
        "attack_model = define_attack_model()\n",
        "for layer in attack_model.layers:\n",
        "    if not layer.name == \"perturbation\":\n",
        "        layer.trainable = False\n",
        "# setting the weigths\n",
        "attack_model.get_layer(\"Conv2D_1\").set_weights(model.get_layer(\"Conv2D_1\").get_weights())\n",
        "attack_model.get_layer(\"Conv2D_2\").set_weights(model.get_layer(\"Conv2D_2\").get_weights())\n",
        "attack_model.get_layer(\"Dense_1\").set_weights(model.get_layer(\"Dense_1\").get_weights())\n",
        "attack_model.get_layer(\"Dense_2\").set_weights(model.get_layer(\"Dense_2\").get_weights())\n",
        "taget_three = np.array([[[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]])\n",
        "attack_model.compile(loss=custom_loss, optimizer='adam', metrics=['accuracy'])\n",
        "attack_model.fit(test_images[:1], taget_three, epochs=100, verbose=False)\n",
        "perturbation_layer = attack_model.get_layer('perturbation')\n",
        "# Evaluate the attack model on the first test image\n",
        "optimized_perturbation = np.array(perturbation_layer.get_weights())\n",
        "adv_example = test_images[:1] + optimized_perturbation.reshape(1, 28, 28)\n",
        "# Clip the adversarial example to the range of valid inputs\n",
        "adv_example = np.clip(adv_example, 0.0, 1.0)\n",
        "\n",
        "# Verify if the adversarial example is classified as \"3\"\n",
        "predictions = model.predict(adv_example)\n",
        "print('Predicted class:', np.argmax(predictions))\n",
        "print(f'The Norm of the perturbation is {tf.norm(optimized_perturbation)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2dd2200ddd0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "im = Image.fromarray(np.uint8(255*cm.gray(np.squeeze(adv_example))))\n",
        "plt.imshow(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "also another way below :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = (x_train / 255) - 0.5\n",
        "x_train = tf.reshape(x_train, (-1, 28, 28, 1))\n",
        "x_test = (x_test / 255) - 0.5\n",
        "x_test = tf.reshape(x_test, (-1, 28, 28, 1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 32s 60ms/step - loss: nan - categorical_accuracy: 0.9915\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 29s 63ms/step - loss: nan - categorical_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 28s 59ms/step - loss: nan - categorical_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 28s 59ms/step - loss: nan - categorical_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 28s 60ms/step - loss: nan - categorical_accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1d123c94990>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class CNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Architecture taken from Carlini and Wagner 2016\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"Hyperparameters\"\"\"\n",
        "        super().__init__()\n",
        "        # LearningRate0.1\n",
        "        self.learning_rate = 0.1\n",
        "        # Momentum0.9\n",
        "        self.momentum = 0.9\n",
        "        # DelayRate-\n",
        "        # Dropout0.5\n",
        "        self.dropout = 0.5\n",
        "        # BatchSize128\n",
        "        self.batch_size = 128\n",
        "        # Epochs50\n",
        "        self.epochs = 5\n",
        "\n",
        "        # visualize loss over time\n",
        "        self.loss_list = []\n",
        "        # momentum-based SGD optimizer\n",
        "        self.optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=self.learning_rate, momentum=self.momentum)\n",
        "\n",
        "\n",
        "        \"\"\"Architecture\"\"\"\n",
        "        # Convolution+ReLU3×3×32\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')\n",
        "        # Convolution+ReLU3×3×32\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')\n",
        "        # MaxPooling2×2\n",
        "        self.maxpool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        # Convolution+ReLU3×3×64\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')\n",
        "        # Convolution+ReLU3×3×64\n",
        "        self.conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')\n",
        "        # MaxPooling2×2\n",
        "        self.maxpool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        # FullyConnected+ReLU200\n",
        "        self.fc1 = tf.keras.layers.Dense(units=200, activation='relu')\n",
        "        # FullyConnected+ReLU200\n",
        "        self.fc2 = tf.keras.layers.Dense(units=200, activation='relu')\n",
        "        # Dense(10)\n",
        "        self.fc3 = tf.keras.layers.Dense(10)\n",
        "        # Softmax10\n",
        "        self.softmax = tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, is_testing=False):\n",
        "        \"\"\"\n",
        "        Runs a forward pass on the network\n",
        "\n",
        "        :param inputs: input images\n",
        "        :param is_testing: if True, we do not apply dropout\n",
        "        :return: output of the network\n",
        "        \"\"\"\n",
        "\n",
        "        # Convolution+ReLU3×3×32\n",
        "        x = self.conv1(inputs)\n",
        "        # Convolution+ReLU3×3×32\n",
        "        x = self.conv2(x)\n",
        "        # MaxPooling2×2\n",
        "        x = self.maxpool1(x)\n",
        "        # Convolution+ReLU3×3×64\n",
        "        x = self.conv3(x)\n",
        "        # Convolution+ReLU3×3×64\n",
        "        x = self.conv4(x)\n",
        "        # MaxPooling2×2\n",
        "        x = self.maxpool2(x)\n",
        "        # Flatten\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "        # FullyConnected+ReLU200\n",
        "        x = self.fc1(x)\n",
        "        # FullyConnected+ReLU200\n",
        "        x = self.fc2(x)\n",
        "        # Dense 10\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def loss(self, labels, logits):\n",
        "        \"\"\"\n",
        "        Computes the loss of the network\n",
        "        The loss is the cross entropy loss of the network\n",
        "\n",
        "\n",
        "        :param logits: output of the network\n",
        "        :param labels: true labels\n",
        "        :return: loss\n",
        "        \"\"\"\n",
        "\n",
        "        cce = tf.nn.softmax_cross_entropy_with_logits(labels, logits)\n",
        "        return tf.reduce_mean(cce)\n",
        "\n",
        "\n",
        "model = CNN()\n",
        "model.compile(loss=model.loss, optimizer=model.optimizer, metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "model.fit(x_train, y_train, batch_size=model.batch_size, epochs=model.epochs, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([[nan nan nan nan nan nan nan nan nan nan]], shape=(1, 10), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm  # shows progress bar during training\n",
        "import pickle as pk\n",
        "\n",
        "class L2Attack:\n",
        "\n",
        "    def __init__(self, model, **kwargs):\n",
        "        self.model = model  # NOTE the model must return logits\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=kwargs[\"learning_rate\"])\n",
        "        self.c = kwargs[\"c\"]\n",
        "        self.num_epochs = kwargs[\"num_epochs\"]\n",
        "        self.threshold_dist = kwargs[\"threshold_dist\"]\n",
        "        self.threshold_f = kwargs[\"threshold_f\"]\n",
        "\n",
        "    def __call__(self, x, target):\n",
        "        \"\"\"\n",
        "        :param x: input image\n",
        "        :param target: integer corresponding to label target classification\n",
        "        :return xp: perturbed image that makes the model classify it as the target classification\n",
        "        \"\"\"\n",
        "        # initialize w to be a random image\n",
        "        x = tf.cast(x, dtype=tf.float32)\n",
        "        w = tf.Variable(tf.random.normal(tf.shape(x)), dtype=tf.float32)\n",
        "\n",
        "        # if num_epochs is None, run until the thresholds are reached\n",
        "        if self.num_epochs is None:\n",
        "            # run one iteration to get initial values\n",
        "            dist_loss, f_loss, _ = self.train(x, target, w)\n",
        "            epoch = 0\n",
        "            # run until thresholds are reached\n",
        "            while (dist_loss > self.threshold_dist) or (f_loss > self.threshold_f):\n",
        "                dist_loss, f_loss, _ = self.train(x, target, w)\n",
        "                pred = self.model_prediction(w)[0]\n",
        "                print(f\"Epoch {epoch} | dist loss {dist_loss:.3f} | f loss {f_loss:.3f} | model pred {pred}\")\n",
        "                epoch += 1\n",
        "            # the perturbed image is modified by the tanh function\n",
        "            xp = 0.5 * (tf.tanh(w) + 1)\n",
        "            return xp\n",
        "        else:\n",
        "            # otherwise, run for num_epochs iterations\n",
        "            for _ in range(self.num_epochs):\n",
        "                dist_loss, f_loss, _ = self.train(x, target, w)\n",
        "                pred = self.model_prediction(w)\n",
        "            xp = 0.5 * (tf.tanh(w) + 1)\n",
        "            return xp\n",
        "\n",
        "    def f(self, xp, target):\n",
        "        \"\"\"\n",
        "        This is the function f that is minimized to ensure that the perturbed image\n",
        "        attacks the model successfully\n",
        "\n",
        "        f(x)= max(max{Z(x)i: i!=t} - Z(x)t, −κ)\n",
        "\n",
        "        Z is the output of the model, Z(x)i is the ith element of Z(x), and t is the target class.\n",
        "        κ is a constant that controls the confidence of the attack; we set κ = 0 in all experiments.\n",
        "\n",
        "        :param xp: perturbed image of size [BATCH_SIZE, WIDTH, HEIGHT, NUM_CHANNELS]\n",
        "        :param target: integer corresponding to label of target classification\n",
        "        \"\"\"\n",
        "        xp = tf.expand_dims(xp, axis=0)\n",
        "        Z = self.model(xp)\n",
        "        print(Z)\n",
        "        Z = tf.reshape(Z, [10])\n",
        "        Zt = Z[target]\n",
        "        Z = tf.concat([Z[:target], Z[target+1:]], axis=0)  # i != t\n",
        "        ret = tf.reduce_max(Z) - Zt\n",
        "        return tf.maximum(0.0, ret)\n",
        "\n",
        "    def train(self, x, target, w):\n",
        "        \"\"\"\n",
        "        Performs one iteration of optimizing the objective function\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            delta = 0.5 * (tf.tanh(w) + 1) - x\n",
        "            dist_loss = tf.square(tf.norm(delta, ord=\"euclidean\"))\n",
        "            f_loss = self.f(delta + x, target)\n",
        "            total_loss = dist_loss + self.c * f_loss\n",
        "        gradients = tape.gradient(total_loss, w)\n",
        "        self.optimizer.apply_gradients(zip([gradients], [w]))\n",
        "        return dist_loss, f_loss, total_loss\n",
        "\n",
        "    def model_prediction(self, w):\n",
        "        \"\"\"\n",
        "        For debugging information. Given w, finds the model's prediction on w.\n",
        "        \"\"\"\n",
        "        xp = 0.5 * (tf.tanh(w) + 1)\n",
        "        xp = tf.expand_dims(xp, axis=0)\n",
        "        pred = self.model(xp)\n",
        "        pred = tf.nn.softmax(pred, axis=1)\n",
        "        return tf.argmax(pred, axis=1)\n",
        "    \n",
        "\n",
        "kwargs = {\n",
        "        \"c\": 10,\n",
        "        \"learning_rate\": 1e-2,\n",
        "        \"num_epochs\": 1,  # If None, attack runs until it reaches the thresholds\n",
        "        \"threshold_dist\": 170.0,\n",
        "        \"threshold_f\": 0.01\n",
        "    }\n",
        "attack = L2Attack(model, **kwargs)\n",
        "xp = attack(x_test[0], 3)\n",
        "with open(\"./output.pk\", \"wb\") as fd:\n",
        "    pk.dump(xp, fd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "some errors that I did not have time to debugg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicted class: 7\n",
            "The Norm of the perturbation is 0.5863823294639587\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x2dd08516750>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the Hoyer-Square regularizer for element-wise pruning\n",
        "class HoyerSquareRegularizer(tf.keras.regularizers.Regularizer):\n",
        "    def __init__(self, weight):\n",
        "        self.weight = weight\n",
        "\n",
        "    def __call__(self, x):\n",
        "        sum_abs = tf.reduce_sum(tf.abs(x))**2\n",
        "        sum_squared = tf.reduce_sum(tf.square(x))\n",
        "        return self.weight * tf.square(sum_abs) / (sum_squared + tf.keras.backend.epsilon())\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'weight': self.weight}\n",
        "\n",
        "# Define the model with Hoyer-Square regularizer\n",
        "def define_model_with_regularizer(weight):\n",
        "    inputs = tf.keras.Input(shape=(28, 28, 1), name='inputs')\n",
        "    # Perturbation layer with 28*28 learnable weights\n",
        "    perturbation = tf.keras.layers.Conv2D(1, kernel_size=(28, 28), activation='linear', use_bias=False, name=\"perturbation\",\n",
        "                                        kernel_regularizer=HoyerSquareRegularizer(weight))(inputs)\n",
        "    \n",
        "    # Add perturbation to the input\n",
        "    x = layers.Add(name=\"addition\")([inputs, perturbation])\n",
        "    x = tf.keras.layers.Conv2D(32, kernel_size=3, activation='relu', name=\"Conv2D_1\")(x)\n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu', name=\"Conv2D_2\")(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(\n",
        "        128,\n",
        "        activation='relu',\n",
        "        name=\"Dense_1\"\n",
        "    )(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    outputs = tf.keras.layers.Dense(10, name=\"Dense_2\")(x)  # no softmax\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Load and preprocess training data (MNIST)\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
        "\n",
        "\n",
        "# Define and train the attack model\n",
        "# Define and train model with Hoyer-Square regularizer for element-wise pruning\n",
        "weight = 0.1  # Adjust the weight according to your needs\n",
        "attack_model = define_model_with_regularizer(weight)\n",
        "attack_model.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "for layer in attack_model.layers:\n",
        "    if not layer.name == \"perturbation\":\n",
        "        layer.trainable = False\n",
        "# setting the weigths\n",
        "attack_model.get_layer(\"Conv2D_1\").set_weights(model.get_layer(\"Conv2D_1\").get_weights())\n",
        "attack_model.get_layer(\"Conv2D_2\").set_weights(model.get_layer(\"Conv2D_2\").get_weights())\n",
        "attack_model.get_layer(\"Dense_1\").set_weights(model.get_layer(\"Dense_1\").get_weights())\n",
        "attack_model.get_layer(\"Dense_2\").set_weights(model.get_layer(\"Dense_2\").get_weights())\n",
        "taget_three = np.array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
        "attack_model.fit(test_images[:1], taget_three, epochs=20, verbose=False)\n",
        "perturbation_layer = attack_model.get_layer('perturbation')\n",
        "# Evaluate the attack model on the first test image\n",
        "optimized_perturbation = np.array(perturbation_layer.get_weights())\n",
        "adv_example = test_images[:1] + optimized_perturbation.reshape(1, 28, 28)\n",
        "# Clip the adversarial example to the range of valid inputs\n",
        "adv_example = np.clip(adv_example, 0.0, 1.0)\n",
        "\n",
        "# Verify if the adversarial example is classified as \"3\"\n",
        "predictions = model.predict(adv_example)\n",
        "print('Predicted class:', np.argmax(predictions))\n",
        "print(f'The Norm of the perturbation is {tf.norm(optimized_perturbation)}')\n",
        "\n",
        "im = Image.fromarray(np.uint8(255*cm.gray(np.squeeze(adv_example))))\n",
        "plt.imshow(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Ex10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
