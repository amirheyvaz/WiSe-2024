{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Machine Learning Lab\n",
    "# Exercise 11\n",
    "\n",
    "**General Instructions:**\n",
    "\n",
    "1. You need to submit the PDF as well as the filled notebook file.\n",
    "1. Name your submissions by prefixing your matriculation number to the filename. Example, if your MR is 12345 then rename the files as **\"12345_Exercise_11.xxx\"**\n",
    "1. Complete all your tasks and then do a clean run before generating the final PDF. (_Clear All Ouputs_ and _Run All_ commands in Jupyter notebook)\n",
    "\n",
    "**Exercise Specific instructions::**\n",
    "\n",
    "1. You are allowed to use only NumPy and Pandas (unless stated otherwise). You can use any library for visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you will be using the credit card fraud detection dataset from https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud to train and test a Support Vector Machine (SVM) classifier. Your task\n",
    "is to:\n",
    "\n",
    "1. Download the data and split the dataset into training and testing sets (80-20 split) in a stratified manner to take care of the class imbalance. You need to code the stratified splitting function from scratch. *sklearn is not allowed for this part*\n",
    "1. Implement the basic Pegasos Algorithm from the paper https://home.ttic.edu/~nati/Publications/PegasosMPB.pdf. This is in page 5, Fig 1.\n",
    "1. Implement the mini-batch Pegasos algorithm from the paper https://home.ttic.edu/~nati/Publications/PegasosMPB.pdf. Do not forget the projection step. This is in page 6, Fig 2.\n",
    "1. Implement the dual coordinate descent method for SVMâ€™s from the paper https://icml.cc/Conferences/2008/papers/166.pdf. This is Algorithm 1 in the paper.\n",
    "1. Report a final accuracy on the test set for all 3 approches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "\n",
    "def StratifiedSplit(X, y, test_size=0.3):\n",
    "    unique_classes = np.unique(y)\n",
    "    \n",
    "    train_indices, test_indices = [], []\n",
    "    \n",
    "    for class_label in unique_classes:\n",
    "        # Find indices of samples with the current class label\n",
    "        class_indices = np.where(y == class_label)[0]\n",
    "        np.random.shuffle(class_indices)\n",
    "        \n",
    "        # Calculate the number of samples for the test set\n",
    "        num_test_samples = int(len(class_indices) * test_size)\n",
    "        \n",
    "        # Split indices into train and test sets\n",
    "        train_indices.extend(class_indices[num_test_samples:])\n",
    "        test_indices.extend(class_indices[:num_test_samples])\n",
    "    \n",
    "    # Shuffle the indices to randomize the order\n",
    "    np.random.shuffle(train_indices)\n",
    "    np.random.shuffle(test_indices)\n",
    "    \n",
    "    # Create the train and test sets based on the indices\n",
    "    X_train, X_test = X[train_indices,:], X[test_indices,:]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# reading the file\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "# separating into X and Y\n",
    "X = df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "y = df.iloc[:,-1].values\n",
    "# make the y labels as -1,1 instead of 0,1\n",
    "y = np.where(y>0,y,-1)\n",
    "X_train, X_test, y_train, y_test = StratifiedSplit(X.values, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pegasos:\n",
    "    def __init__ (self, lamda, k, projection):\n",
    "        self.lamda = lamda #lambda value\n",
    "        self.k = k #number of observations to be used\n",
    "        self.projection = projection #for projections\n",
    "        \n",
    "    def gradient(self, p): #to calculate the gradient\n",
    "        return np.where(p<1,1,0)\n",
    "    \n",
    "    def fit(self, x, y, n_iters=1500):\n",
    "        m, n = x.shape\n",
    "        self.W = np.zeros(n)\n",
    "        for t in range(1,n_iters+1): #iterate till max_iters\n",
    "            #pick a random instance\n",
    "            idx = np.random.choice(range(m), self.k, replace=False)\n",
    "            lr = 1/(self.lamda*t) #get the learning rate\n",
    "            x_i = x[idx] #get x_i\n",
    "            y_i = y[idx] #get y_i\n",
    "            prod = y_i * (x_i@self.W) #obtain the product\n",
    "            #update the weights\n",
    "            self.W = (1-lr*self.lamda)*self.W + \\\n",
    "            (lr/self.k)*(np.sum(np.multiply(y_i.reshape(-1,1),x_i)*self.gradient(prod).reshape(-1,1),axis=0))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        #transform the inputs using the weight vector\n",
    "        p = x@self.W.reshape(-1,1)\n",
    "        return np.sign(p) #the sign function outputs the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMDC:\n",
    "    def __init__ (self, C, mode = \"L1\", tol=1e-3):\n",
    "        self.C = C #C value\n",
    "        self.mode = mode\n",
    "        self.tol = tol #tolerance value to break out of the loop\n",
    "    \n",
    "    def partial_gradient(self,G,a,U): #to calculate the partial gradient\n",
    "        if a == 0:\n",
    "            return min(G,0)\n",
    "        elif a == U:\n",
    "            return max(G,0)\n",
    "        elif (a>0) and (a<U):\n",
    "            return G\n",
    "    \n",
    "    def fit(self, X, y,iters=100):\n",
    "        m, n = X.shape\n",
    "        self.w = 0 #weight matrix\n",
    "        \n",
    "        #SVMDC can be done in L1 and L2 modes\n",
    "        if self.mode == \"L1\":\n",
    "            Dii = 0\n",
    "            U=self.C\n",
    "        else:\n",
    "            Dii = 1/(2*self.C)\n",
    "            U=np.inf\n",
    "        \n",
    "        #to get the langrangian multipliers\n",
    "        alpha = np.zeros(m)\n",
    "        self.w = np.zeros(shape=(n)) #initialize the weight matrix\n",
    "        Qii = np.sum(X**2, 1) + Dii #calculate Qii\n",
    "        for t in range(iters): #iterate till max_iters\n",
    "            err = 0 #calculate error to break the loop\n",
    "            for i in range(m): #iterate over each instance\n",
    "                Qhat = Qii[i] #get Q_bar\n",
    "                G = np.multiply(np.dot(self.w,X[i,:]),y[i]) - 1 + Dii * alpha[i] #gradient of the objective function\n",
    "                PG = self.partial_gradient(G,alpha[i],U) #partial gradient of the objective function\n",
    "                if np.abs(G) > err: #to keep updating the error term\n",
    "                    err = np.abs(G)\n",
    "                \n",
    "                #to find optimal solution\n",
    "                if np.abs(G) > 0: \n",
    "                    alpha_new = min(max(alpha[i]-G/Qhat,0),U)\n",
    "                    self.w = self.w+(np.multiply((alpha_new - alpha[i])* y[i] ,X[i,:]))\n",
    "                    alpha[i] = alpha_new\n",
    "            \n",
    "            #stop iterating once the error fall below tolerance        \n",
    "            if err<self.tol:\n",
    "                break\n",
    "        \n",
    "    def predict(self, x):\n",
    "        #project the points using the weight matrix\n",
    "        p = x@self.w.reshape(-1,1)\n",
    "        return np.sign(p) #the sign function tells the class which the object belong to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Basic Pegasos is 0.9982795245869981 and ROC AUC Score is 0.5\n"
     ]
    }
   ],
   "source": [
    "# Pegasos Basic\n",
    "peg_basic = Pegasos(0.01,1,projection=False)\n",
    "peg_basic.fit(X_train,y_train)\n",
    "\n",
    "# Test the model\n",
    "print(f'Accuracy of Basic Pegasos is {accuracy_score(y_test,peg_basic.predict(X_test))} and ROC AUC Score is {roc_auc_score(y_test,peg_basic.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Batch Pegasos is 0.9982795245869981 and ROC AUC Score is 0.5\n"
     ]
    }
   ],
   "source": [
    "# Pegasos Batch\n",
    "peg_batch = Pegasos(0.01,10,projection=False)\n",
    "peg_batch.fit(X_train,y_train)\n",
    "# Test the model\n",
    "print(f'Accuracy of Batch Pegasos is {accuracy_score(y_test,peg_batch.predict(X_test))} and ROC AUC Score is {roc_auc_score(y_test,peg_batch.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dual Coordinate Descent\n",
    "svm = SVMDC(0.1)\n",
    "svm.fit(X_train,y_train)\n",
    "# Test the model\n",
    "print(f'Accuracy of Dual Coordinate Descent SVM is {accuracy_score(y_test,svm.predict(X_test))} and ROC AUC Score is {roc_auc_score(y_test,svm.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Here, since we have a huge class imbalance in the dataset, therefore, a better approach would be to use some techniques like Oversampling, Undersampling, and SMOTE as a preprocessing step and then apply the model over the preprocessed dataset. Additionally, Pegasos and CD uses stochastic optimization approach therefore the results obtained after these techniques may differ largely for each run and for the choice of each random state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
