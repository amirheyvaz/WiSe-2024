{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Machine Learning Lab\n",
    "# Exercise 08\n",
    "\n",
    "**General Instructions:**\n",
    "\n",
    "1. You need to submit the PDF as well as the filled notebook file.\n",
    "1. Name your submissions by prefixing your matriculation number to the filename. Example, if your MR is 12345 then rename the files as **\"12345_Exercise_11.xxx\"**\n",
    "1. Complete all your tasks and then do a clean run before generating the final PDF. (_Clear All Ouputs_ and _Run All_ commands in Jupyter notebook)\n",
    "\n",
    "**Exercise Specific instructions::**\n",
    "\n",
    "1. You are allowed to use only NumPy and Pandas (unless stated otherwise). You can use any library for visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF and BOW**\n",
    "\n",
    "In this part, you will be working with the IMBD movie review dataset to perform various natural language processing tasks. You need to get the dataset from https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "\n",
    "1. Download and read the dataset (subset the data to only use 10,000 rows).\n",
    "1. Perform tokenization on the review text.\n",
    "1. Remove stop words from the tokenized text.\n",
    "1. Use regular expressions to clean the text, removing any HTML tags, emails, and other unnecessary information.\n",
    "1. Convert the cleaned data into a TF-IDF and BOW representation from scratch.\n",
    "\n",
    "*Note: you can use NLTK for all sub-parts except the last*\n",
    "\n",
    "**Main task**:\n",
    "Using the BOW and Tf-Idf representation, implement a Naive-Bayes classifier for the data from scratch. Use Laplace smoothing for the implementation **Do not use sklearn for this part** \n",
    "\n",
    "[Reference Slide](https://www.ismll.uni-hildesheim.de/lehre/ml-16w/script/ml-09-A8-bayesian-networks.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download the dataset from https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "# Load the dataset and subset it to 10,000 rows\n",
    "df = pd.read_csv('IMDB Dataset.csv', header=0, index_col=None)\n",
    "df = df.sample(n=10000, random_state=42)\n",
    "\n",
    "# Clean text using regular expressions\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove emails\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "    # Remove other unnecessary information\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['review'].apply(clean_text)\n",
    "\n",
    "# Tokenization\n",
    "df['tokenized_text'] = df['cleaned_text'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['filtered_text'] = df['tokenized_text'].apply(lambda x: [word for word in x if word.isalpha() and word not in stop_words])\n",
    "\n",
    "# Prepare data for classification\n",
    "train_data = df['filtered_text'].to_numpy()[:8000]\n",
    "test_data = df['filtered_text'].to_numpy()[8000:]\n",
    "train_target = df['sentiment'].to_numpy()[:8000]\n",
    "test_target = df['sentiment'].to_numpy()[8000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8395\n"
     ]
    }
   ],
   "source": [
    "# Naive-Bayes classifier using BOW representation with Laplace smoothing\n",
    "def train_naive_bayes_bow(data, target):\n",
    "    vocabulary = set([word for sublist in data for word in sublist])\n",
    "    word_counts = defaultdict(int)\n",
    "    class_counts = defaultdict(int)\n",
    "    total_docs = len(data)\n",
    "    \n",
    "    for i in range(total_docs):\n",
    "        current_class = target[i]\n",
    "        class_counts[current_class] += 1\n",
    "        \n",
    "        for word in data[i]:\n",
    "            word_counts[(word, current_class)] += 1\n",
    "    \n",
    "    return vocabulary, word_counts, class_counts, total_docs\n",
    "\n",
    "def predict_naive_bayes_bow(vocabulary, word_counts, class_counts, total_docs, number_of_unique_words_in_each_class, document, alpha=1):\n",
    "    scores = defaultdict(float)\n",
    "    \n",
    "    # c is the class label in this iteration\n",
    "    for c in class_counts:\n",
    "        scores[c] = (class_counts[c] / total_docs)\n",
    "        for word in document:\n",
    "            scores[c] *= ((word_counts[(word, c)] + alpha) / (number_of_unique_words_in_each_class[c] + alpha * len(vocabulary))) * 10000\n",
    "    # # Normalize scores array\n",
    "    total_score = sum(scores.values())\n",
    "    normalized_scores = {label: score / total_score for label, score in scores.items()}\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = max(normalized_scores, key=normalized_scores.get)\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Train the Naive-Bayes classifier with BOW representation\n",
    "vocabulary, word_counts_per_class, class_counts, total_docs = train_naive_bayes_bow(train_data, train_target)\n",
    "number_of_unique_words_in_each_class = defaultdict(int)\n",
    "for t, count in word_counts_per_class.items():\n",
    "    word = t[0]\n",
    "    class_label = t[1]\n",
    "    number_of_unique_words_in_each_class[class_label] += count\n",
    "\n",
    "# Test the Naive-Bayes classifier on the test set\n",
    "correct_predictions = 0\n",
    "for i in range(len(test_data)):\n",
    "    prediction = predict_naive_bayes_bow(vocabulary, word_counts_per_class, class_counts, total_docs, number_of_unique_words_in_each_class, test_data[i])\n",
    "    if prediction == test_target[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(test_data)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_tf_idf(data):\n",
    "    # Calculate TF (Term Frequency)\n",
    "    tf = defaultdict(lambda: defaultdict(float))\n",
    "    for i in range(len(data)):\n",
    "        for word in data[i]:\n",
    "            tf[i][word] += 1 / len(data[i])\n",
    "    \n",
    "    # Calculate IDF (Inverse Document Frequency)\n",
    "    idf = defaultdict(float)\n",
    "    for doc in tf:\n",
    "        for word in tf[doc]:\n",
    "            idf[word] += 1\n",
    "    \n",
    "    for word in idf:\n",
    "        idf[word] = math.log(len(data) / (idf[word] + 1))\n",
    "    \n",
    "    # Calculate TF-IDF\n",
    "    tf_idf = defaultdict(lambda: defaultdict(float))\n",
    "    for doc in tf:\n",
    "        for word in tf[doc]:\n",
    "            tf_idf[doc][word] = tf[doc][word] * idf[word]\n",
    "    \n",
    "    return tf_idf\n",
    "\n",
    "def train_naive_bayes_tfidf(data, target):\n",
    "    tf_idf = calculate_tf_idf(data)\n",
    "    class_counts = defaultdict(int)\n",
    "    total_docs = len(data)\n",
    "    \n",
    "    for i in range(total_docs):\n",
    "        current_class = target[i]\n",
    "        class_counts[current_class] += 1\n",
    "    \n",
    "    return tf_idf, class_counts, total_docs\n",
    "\n",
    "def predict_naive_bayes_tfidf(tf_idf, target, class_counts, total_docs, document, alpha=1):\n",
    "    scores = defaultdict(float)\n",
    "    \n",
    "    # c is the class label in this iteration\n",
    "    for c in class_counts:\n",
    "        scores[c] = (class_counts[c] / total_docs)\n",
    "        for word in document:\n",
    "            scores[c] *= ((tf_idf.get(word, 0) + alpha) / (sum(tf_idf[i][word] for i in tf_idf) + alpha)) * 1000\n",
    "    \n",
    "    # Normalize scores array\n",
    "    total_score = sum(scores.values())\n",
    "    normalized_scores = {label: score / total_score for label, score in scores.items()}\n",
    "    \n",
    "    # Get the class with the highest probability\n",
    "    predicted_class = max(normalized_scores, key=normalized_scores.get)\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Train the Naive-Bayes classifier with TF-IDF representation\n",
    "tf_idf, class_counts, total_docs = train_naive_bayes_tfidf(train_data, train_target)\n",
    "\n",
    "# Test the Naive-Bayes classifier on the test set\n",
    "correct_predictions = 0\n",
    "for i in range(len(test_data)):\n",
    "    prediction = predict_naive_bayes_tfidf(tf_idf, train_target, class_counts, total_docs, test_data[i])\n",
    "    if prediction == test_target[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / len(test_data)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**\n",
    "\n",
    "Use sklearn implementation of Naive-Bayes classifier and compare the results with your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Naive-Bayes Classifier (with BOW representation) Accuracy: 0.8415\n",
      "Sklearn Naive-Bayes Classifier Accuracy (with TF-IDF representation): 0.853\n"
     ]
    }
   ],
   "source": [
    "### Your code here\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv('IMDB Dataset.csv', header=0, index_col=None)\n",
    "df = df.sample(n=10000, random_state=42)\n",
    "\n",
    "# Clean text using regular expressions\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove emails\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "    # Remove other unnecessary information\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['review'].apply(clean_text)\n",
    "stop_words = list(stopwords.words('english'))\n",
    "vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_sklearn = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Sklearn Naive-Bayes Classifier (with BOW representation) Accuracy: {accuracy_sklearn}\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the sklearn implementation\n",
    "accuracy_sklearn = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Sklearn Naive-Bayes Classifier Accuracy (with TF-IDF representation): {accuracy_sklearn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N-gram Language Model**\n",
    "\n",
    "\n",
    "You won't believe what happened ??? !\n",
    "\n",
    "Is the word \"next\" on the tip of your tongue? Although there are other possibilities, that is undoubtedly the most likely one. Other options are \"after\", \"after that\", and \"to them\". Our intuition tells us that some sentence endings are more plausible than others, especially when we take into account the previous information, the location of the phrase, and the speaker or author.\n",
    "\n",
    "N-gram language models simply formalize that intuition. An n-gram model gives each possibility a probability score by solely taking into account the words that came before it. The probability of the word \"next\" in our example may be 80\\%, whereas the probabilities of the words \"after\" and \"then\" might be 10\\%, 5\\%, and 5\\%, respectively.\n",
    "\n",
    "By leveraging these statistics, n-grams fuel the development of language models, which in turn contribute to an overall speech recognition system.\n",
    "\n",
    "**Main task**:\n",
    "\n",
    "In this part you are tasked with coding a N-gram language model on the dataset (https://www.kaggle.com/datasets/nltkdata/europarl). Use the english language for the task.\n",
    "\n",
    "\n",
    "Evaluate your model based on perplexity and generate sentences using n-grams with n={2,3,4,5}. \n",
    "\n",
    "*Reading Material: https://web.stanford.edu/~jurafsky/slp3/3.pdf*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Amir\n",
      "[nltk_data]     Hossein\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unsupported type for looking up in vocabulary: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Train and evaluate models for N={2, 3, 4, 5}\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m---> 52\u001b[0m     model, perplexity \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_ngram_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Perplexity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperplexity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# Generate sentences using the trained model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[40], line 46\u001b[0m, in \u001b[0;36mtrain_and_evaluate_ngram_model\u001b[1;34m(n, train_data, test_data)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Test the model on the test dataset\u001b[39;00m\n\u001b[0;32m     45\u001b[0m ngrams_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ngrams(test_data, n, pad_left\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, pad_right\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m---> 46\u001b[0m perplexity \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperplexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mngrams_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, perplexity\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\nltk\\lm\\api.py:180\u001b[0m, in \u001b[0;36mLanguageModel.perplexity\u001b[1;34m(self, text_ngrams)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperplexity\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_ngrams):\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculates the perplexity of the given text.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    This is simply 2 ** cross-entropy for the text, so the arguments are the same.\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mpow\u001b[39m(\u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_ngrams\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\nltk\\lm\\api.py:171\u001b[0m, in \u001b[0;36mLanguageModel.entropy\u001b[1;34m(self, text_ngrams)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentropy\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_ngrams):\n\u001b[0;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate cross-entropy of model for given evaluation text.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m    :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    :rtype: float\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m _mean(\n\u001b[1;32m--> 171\u001b[0m         \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mngram\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mngram\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mngram\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_ngrams\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    172\u001b[0m     )\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\nltk\\lm\\api.py:171\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentropy\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_ngrams):\n\u001b[0;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate cross-entropy of model for given evaluation text.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m    :param Iterable(tuple(str)) text_ngrams: A sequence of ngram tuples.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    :rtype: float\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m _mean(\n\u001b[1;32m--> 171\u001b[0m         [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mngram\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mngram\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ngram \u001b[38;5;129;01min\u001b[39;00m text_ngrams]\n\u001b[0;32m    172\u001b[0m     )\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\nltk\\lm\\api.py:150\u001b[0m, in \u001b[0;36mLanguageModel.logscore\u001b[1;34m(self, word, context)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogscore\u001b[39m(\u001b[38;5;28mself\u001b[39m, word, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the log score of this word in this context.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m    The arguments are the same as for `score` and `unmasked_score`.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_base2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\nltk\\lm\\api.py:125\u001b[0m, in \u001b[0;36mLanguageModel.score\u001b[1;34m(self, word, context)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(\u001b[38;5;28mself\u001b[39m, word, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Masks out of vocab (OOV) words and computes their model score.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    For model-specific logic of calculating scores, see the `unmasked_score`\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    method.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munmasked_score(\n\u001b[1;32m--> 125\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mlookup(word), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     )\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\nltk\\lm\\vocabulary.py:186\u001b[0m, in \u001b[0;36mVocabulary.lookup\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlookup\u001b[39m(\u001b[38;5;28mself\u001b[39m, words):\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Look up one or more words in the vocabulary.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    If passed one word as a string will return that word or `self.unk_label`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dispatched_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Program Files\\Python311\\Lib\\functools.py:909\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    907\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\nltk\\lm\\vocabulary.py:28\u001b[0m, in \u001b[0;36m_\u001b[1;34m(words, vocab)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;129m@_dispatched_lookup\u001b[39m\u001b[38;5;241m.\u001b[39mregister(Iterable)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(words, vocab):\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Look up a sequence of words in the vocabulary.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    Returns an iterator over looked up words.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(_dispatched_lookup(w, vocab) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words)\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\nltk\\lm\\vocabulary.py:28\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;129m@_dispatched_lookup\u001b[39m\u001b[38;5;241m.\u001b[39mregister(Iterable)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(words, vocab):\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Look up a sequence of words in the vocabulary.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    Returns an iterator over looked up words.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_dispatched_lookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words)\n",
      "File \u001b[1;32mG:\\Program Files\\Python311\\Lib\\functools.py:909\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    907\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mh:\\Uni\\WiSe 2024\\ML LAB\\ml_lab_venv\\Lib\\site-packages\\nltk\\lm\\vocabulary.py:18\u001b[0m, in \u001b[0;36m_dispatched_lookup\u001b[1;34m(words, vocab)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;129m@singledispatch\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dispatched_lookup\u001b[39m(words, vocab):\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported type for looking up in vocabulary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(words)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Unsupported type for looking up in vocabulary: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "### Your code here\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "\n",
    "# Download the dataset if not already downloaded\n",
    "data_folder_path = 'archive_2/europarl_raw/english/'\n",
    "\n",
    "# Function to load data from .en files in a folder\n",
    "def load_data_from_folder(folder_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".en\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                tokens = word_tokenize(text)\n",
    "                tokens = [token for token in tokens if token is not None]\n",
    "                data.append(tokens)\n",
    "    return data\n",
    "\n",
    "# Load data from the local folder\n",
    "tokenized_text = load_data_from_folder(data_folder_path)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(len(tokenized_text) * 0.9)\n",
    "train_data, test_data = tokenized_text[:train_size], tokenized_text[train_size:]\n",
    "\n",
    "# Function to train N-gram model and evaluate perplexity\n",
    "def train_and_evaluate_ngram_model(n, train_data, test_data):\n",
    "    # Create N-grams\n",
    "    ngrams_train, vocab = padded_everygram_pipeline(n, train_data)\n",
    "\n",
    "    # Train the N-gram model\n",
    "    model = MLE(order=n)\n",
    "    model.fit(ngrams_train, vocab)\n",
    "\n",
    "    # Test the model on the test dataset\n",
    "    ngrams_test = list(ngrams(test_data, n, pad_left=True, pad_right=True))\n",
    "    perplexity = model.perplexity(ngrams_test)\n",
    "\n",
    "    return model, perplexity\n",
    "\n",
    "# Train and evaluate models for N={2, 3, 4, 5}\n",
    "for n in range(2, 6):\n",
    "    model, perplexity = train_and_evaluate_ngram_model(n, train_data, test_data)\n",
    "    print(f\"N={n} - Perplexity: {perplexity}\")\n",
    "\n",
    "    # Generate sentences using the trained model\n",
    "    generated_sentence = model.generate(num_words=10, random_seed=42)\n",
    "    print(f\"Generated sentence for N={n}: {' '.join(generated_sentence)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
